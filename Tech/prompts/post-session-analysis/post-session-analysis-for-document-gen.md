
## üìÑ Document Generation Session Review

**Document Specs:**
- Target document: [README.md | Project Outline | etc.]
- Sections completed: [X of Y]
- Final state: [complete | partial | needs revision]

## üìä Session Resource Consumption

**Token Budget Status:**
- Estimated tokens used: ~[X] of ~200,000 available
- Capacity consumed: [X]% 
- Budget health: [HEALTHY <25% | MODERATE 25-60% | ELEVATED 60-80% | CRITICAL >80%]

**Context Window Pressure:**
- Conversation exchanges: [X]
- Average tokens per exchange: ~[X]
- Context density: [LOW | MODERATE | HIGH | SATURATED]
  - LOW: Plenty of room for complexity
  - MODERATE: Normal working range
  - HIGH: Approaching limits, simplify if possible
  - SATURATED: Risk of context loss, consider fresh session

**Rework Overhead:**
- Clean exchanges (first-try success): [X]
- Refinement exchanges (iterations): [X]
- Rework ratio: [X]% (Target: <20%)
- Efficiency rating: [OPTIMAL <10% | GOOD 10-20% | ACCEPTABLE 20-35% | WASTEFUL >35%]

**Conversation Health Indicators:**
- üü¢ **Safe to continue** - All metrics healthy, no concerns
- üü° **Monitor closely** - [specific metric] approaching limits
- üü† **Consider wrapping up** - [specific concern] showing strain
- üî¥ **Start fresh session** - [critical issue] compromising quality

**Over-Optimization Risk Assessment:**
- Unnecessary refinement cycles detected: [count]
- Diminishing returns threshold: [reached/not reached]
- **Verdict:** [LEAN - stopped at good enough | BALANCED - appropriate polish | OVER-OPTIMIZED - chasing perfection]

**Reality Check:**
[One-line assessment: e.g., "You used 3% of available tokens with 15% rework - this session had plenty of headroom, no optimization needed" OR "You're at 72% capacity with high context density - wrap up soon or start fresh"]

**Outline Fidelity:**
- Original outline quality: [clear | adequate | vague]
- Sections that matched outline: [X%]
- Unplanned sections added: [count] (good or bad?)
- Outline drift: [none | minor | significant]
  - Example: [where you deviated and why]

**Progressive Build Quality:**
- Starting point clarity: [1-5]
- Context carried forward: [strong | degraded after section X]
- Tone/voice consistency: [consistent | variable]
- Cross-references accuracy: [all valid | some broken]

**Prompt Efficiency Analysis:**
‚úÖ **Best prompt pattern:**
   - Example: "Prompt #4: 'Write the Installation section, reference the Prerequisites section, use 2nd person imperative'"
   - Why it worked: [specific reason]

‚ö†Ô∏è **Friction points:**
   - Example: "Prompt #7 was too vague, got generic content"
   - Cost: [X] follow-up prompts to correct

**Token Economics:**
- Total tokens (estimate): ~[X]
- Redundant regenerations: ~[X]% of total
- Most expensive section: [which one] ([X] tokens, [Y] attempts)

**Learning Insights:**
üéØ **Outline improvements for next time:**
   - [specific change, e.g., "Pre-define code example formats"]
   
üéØ **Prompt patterns that worked:**
   1. [e.g., "Always specify audience and tone upfront"]
   2. [e.g., "Reference previous sections by name"]

üéØ **What to avoid:**
   - [e.g., "Don't ask for 'comprehensive' without examples"]

**Session Score: [0-100]**
- Outline adherence (25pts): [score]
- First-draft quality (25pts): [score]
- Context retention (25pts): [score]
- Efficiency (25pts): [score]

**Next Session Strategy:**
- [1-2 concrete tactics to try]